{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsnVIoSyjbKiqazUyN9baN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/intanelaqsha/Grievances-Event/blob/main/Scenario_C_fixx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A. SCENARIO C STEP 1**\n",
        "\n",
        "calling all plot/mill mentioned in the grievances."
      ],
      "metadata": {
        "id": "r8H46W-KWE0V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iUIlkjgN2sj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"Grievances-Grid view.csv\", dtype=str).fillna(\"\")\n",
        "\n",
        "# -------------------------\n",
        "# Step 1: Load & normalize\n",
        "# -------------------------\n",
        "\n",
        "def clean_array(x):\n",
        "    if x.strip() == \"\":\n",
        "        return []\n",
        "    return list(dict.fromkeys([i for i in x.split(\",\") if i.strip() != \"\"]))\n",
        "\n",
        "df[\"plots_array\"] = df[\"PIOConcessions-v2\"].apply(lambda s: clean_array(s.replace(\" \", \"\")))\n",
        "df[\"mills_array\"] = df[\"Mills\"].apply(lambda s: clean_array(s.replace(\" \", \"\")))\n",
        "\n",
        "# Source: reproduce DuckDB logic exactly\n",
        "def split_source(src):\n",
        "    if src.strip() == \"\":\n",
        "        return []\n",
        "    tmp = src.replace(\", \", \"<COMMA_SPACE>\")\n",
        "    parts = tmp.split(\",\")\n",
        "    cleaned = [p.strip().replace(\"<COMMA_SPACE>\", \", \") for p in parts if p.strip() != \"\"]\n",
        "    return list(dict.fromkeys(cleaned))\n",
        "\n",
        "df[\"source_array\"] = df[\"Source\"].apply(split_source)\n",
        "\n",
        "df[\"issues_array\"] = df[\"Issues\"].apply(\n",
        "    lambda s: list(dict.fromkeys([i.strip() for i in s.split(\",\") if i.strip() != \"\"]))\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Step 2: Unnest arrays\n",
        "# -------------------------\n",
        "\n",
        "g_plots = df.explode(\"plots_array\")[[\"ID\", \"plots_array\"]].rename(columns={\"plots_array\": \"plot\"})\n",
        "g_mills = df.explode(\"mills_array\")[[\"ID\", \"mills_array\"]].rename(columns={\"mills_array\": \"mill\"})\n",
        "g_issues = df.explode(\"issues_array\")[[\"ID\", \"issues_array\"]].rename(columns={\"issues_array\": \"issue\"})\n",
        "\n",
        "# -------------------------\n",
        "# Step 3: issue category\n",
        "# -------------------------\n",
        "\n",
        "issue_category = pd.DataFrame([\n",
        "    ('Biodiversity loss', 'ENV'), ('Deforestation', 'ENV'), ('Fires', 'ENV'),\n",
        "    ('Illegal Infrastructure', 'ENV'), ('Infrastructure Damage', 'ENV'),\n",
        "    ('Peatland Loss', 'ENV'), ('Riparian Issues', 'ENV'), ('Environmental Pollution', 'ENV'),\n",
        "    ('Corruption', 'SOC'), ('Forced Labor and/or Child Labor', 'SOC'),\n",
        "    ('Gender and Ethnic Disparities', 'SOC'), ('Human Rights Violation', 'SOC'),\n",
        "    ('Indigenous Peoples Conflict', 'SOC'), ('Labor Rights Violations', 'SOC'),\n",
        "    ('Land Dispute', 'SOC'), ('Land Grabbing', 'SOC'), ('Labor Disputes', 'SOC'),\n",
        "    ('Limited Access to Services', 'SOC'), ('Violence and/or Coercion', 'SOC'),\n",
        "    ('Wage Dispute', 'SOC')\n",
        "], columns=[\"issue\", \"category\"])\n",
        "\n",
        "# -------------------------\n",
        "# Step 4: generate group_key\n",
        "# -------------------------\n",
        "\n",
        "plot_issue = g_plots.merge(g_issues, on=\"ID\", how=\"inner\") \\\n",
        "    .merge(issue_category, on=\"issue\", how=\"left\")\n",
        "\n",
        "plot_issue[\"group_key\"] = plot_issue[\"plot\"] + \"_\" + plot_issue[\"category\"].str.lower()\n",
        "\n",
        "mill_issue = g_mills.merge(g_issues, on=\"ID\", how=\"inner\") \\\n",
        "    .merge(issue_category, on=\"issue\", how=\"left\")\n",
        "\n",
        "mill_issue[\"group_key\"] = mill_issue[\"mill\"] + \"_\" + mill_issue[\"category\"].str.lower()\n",
        "\n",
        "# -------------------------\n",
        "# Step 5: union\n",
        "# -------------------------\n",
        "\n",
        "combined = pd.concat([\n",
        "    plot_issue[[\"group_key\", \"ID\"]],\n",
        "    mill_issue[[\"group_key\", \"ID\"]]\n",
        "], ignore_index=True)\n",
        "\n",
        "# -------------------------\n",
        "# Step 6: aggregation (match DuckDB exactly)\n",
        "# -------------------------\n",
        "\n",
        "def flat_unique(series):\n",
        "    out = []\n",
        "    for arr in series:\n",
        "        if isinstance(arr, list):\n",
        "            out.extend(arr)\n",
        "    return list(dict.fromkeys(out))\n",
        "\n",
        "result = (\n",
        "    combined.merge(df, on=\"ID\", how=\"left\")\n",
        "    .groupby(\"group_key\")\n",
        "    .agg({\n",
        "        \"ID\": lambda x: sorted(set(x), key=lambda v: v),   # LIST(DISTINCT ID ORDER BY ID)\n",
        "        \"plots_array\": flat_unique,\n",
        "        \"mills_array\": flat_unique,\n",
        "        \"source_array\": flat_unique,\n",
        "        \"issues_array\": flat_unique,\n",
        "    })\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "result.rename(columns={\"group_key\": \"MHGID\"}, inplace=True)\n",
        "\n",
        "# -------------------------\n",
        "# Step 7: format output\n",
        "# -------------------------\n",
        "\n",
        "def fmt(x):\n",
        "    if isinstance(x, list):\n",
        "        if len(x) == 0:\n",
        "            return \"\"\n",
        "        return \", \".join(str(i) for i in x)\n",
        "    return x\n",
        "\n",
        "for col in [\"ID\", \"plots_array\", \"mills_array\", \"source_array\", \"issues_array\"]:\n",
        "    result[col] = result[col].apply(fmt)\n",
        "\n",
        "result.rename(columns={\n",
        "    \"ID\": \"grievance_IDs\",\n",
        "    \"plots_array\": \"plots\",\n",
        "    \"mills_array\": \"mills\",\n",
        "    \"source_array\": \"sources\",\n",
        "    \"issues_array\": \"issues\"\n",
        "}, inplace=True)\n",
        "\n",
        "# -------------------------\n",
        "# NEW: grievance_count\n",
        "# -------------------------\n",
        "result[\"grievance_count\"] = result[\"grievance_IDs\"].apply(\n",
        "    lambda s: 0 if s == \"\" else len([i.strip() for i in s.split(\",\")])\n",
        ")\n",
        "\n",
        "result.to_csv(\"MHG_Newest_fix.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **B. GROUPING PLOT BY NAME AND AREA PROXIMITY**"
      ],
      "metadata": {
        "id": "Z8gDV-4fWSPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LpmSSnyQSTZ",
        "outputId": "da6a9371-76f0-48da-9905-1dc82e7ed8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USE THIS"
      ],
      "metadata": {
        "id": "WvOqyyEdq57v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2. Check plot proximity (50 km)\n",
        "\n",
        "this already combine step 1 and 2"
      ],
      "metadata": {
        "id": "g-YevvyHWlex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# COMBINED STEP 1 & 2: NAME GROUPING + PROXIMITY REFINE\n",
        "# ======================================================\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from rapidfuzz import fuzz\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "import re\n",
        "\n",
        "# ======================================================\n",
        "# CONFIG\n",
        "# ======================================================\n",
        "INPUT_FILE = \"Concessions-v2-Grid view (5).csv\"\n",
        "GPKG_FILE = \"plots_v2_20251129.gpkg\"\n",
        "OUTPUT_FILE = \"Concessions-with-group-proximity.csv\"\n",
        "\n",
        "FUZZY_THRESHOLD = 90\n",
        "MAX_DIST_KM = 50\n",
        "\n",
        "name_col = \"Name\"\n",
        "id_col = \"ID\"\n",
        "\n",
        "# ======================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ======================================================\n",
        "\n",
        "def clean_id(x):\n",
        "    if pd.isna(x):\n",
        "        return \"UNKNOWN_ID\"\n",
        "    try:\n",
        "        return str(int(float(x)))\n",
        "    except:\n",
        "        return str(x).strip()\n",
        "\n",
        "def normalize_name(x):\n",
        "    if pd.isna(x):\n",
        "        return \"UNKNOWN\"\n",
        "    s = str(x).strip()\n",
        "    if s == \"\":\n",
        "        return \"UNKNOWN\"\n",
        "    if s.lower() == \"unknown\":\n",
        "        return \"UNKNOWN\"\n",
        "    if s.lower().startswith(\"no name\"):\n",
        "        return \"NO_NAME\"\n",
        "    return s\n",
        "\n",
        "def word_difference(a, b):\n",
        "    words_a = a.split()\n",
        "    words_b = b.split()\n",
        "    return len(set(words_a) ^ set(words_b))\n",
        "\n",
        "def extract_base_name(name):\n",
        "    \"\"\"\n",
        "    Extract base name without trailing numbers\n",
        "    'Palong 4' -> 'Palong'\n",
        "    'Estate A 12' -> 'Estate A'\n",
        "    'FELDA Bukit Jalor 1' -> 'FELDA Bukit Jalor'\n",
        "    \"\"\"\n",
        "    # Remove trailing numbers (with optional separators)\n",
        "    base = re.sub(r'\\s+\\d+$', '', name)\n",
        "    return base.strip()\n",
        "\n",
        "def dist_km(a, b):\n",
        "    return a.distance(b) / 1000.0\n",
        "\n",
        "# ======================================================\n",
        "# STEP 1: LOAD & NAME GROUPING\n",
        "# ======================================================\n",
        "df = pd.read_csv(INPUT_FILE)\n",
        "\n",
        "df[id_col] = df[id_col].apply(clean_id)\n",
        "df[name_col] = df[name_col].apply(normalize_name)\n",
        "\n",
        "# Extract base names for comparison\n",
        "df[\"base_name\"] = df[name_col].apply(extract_base_name)\n",
        "\n",
        "# Grouping by name\n",
        "groups = []\n",
        "group_ids = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    name = row[name_col]\n",
        "    base_name = row[\"base_name\"]\n",
        "    pid = row[id_col]\n",
        "\n",
        "    # RULE 1: UNKNOWN or NO NAME → own group\n",
        "    if name == \"UNKNOWN\" or name == \"NO_NAME\":\n",
        "        group_ids.append(f\"{pid}G\")\n",
        "        continue\n",
        "\n",
        "    # RULE 2: PT Perkebunan Nusantara → exact match only\n",
        "    if name.lower().startswith(\"pt perkebunan nusantara\"):\n",
        "        assigned = False\n",
        "        for g in groups:\n",
        "            if g[\"name\"].lower().startswith(\"pt perkebunan nusantara\"):\n",
        "                if word_difference(name, g[\"name\"]) == 0:\n",
        "                    group_ids.append(f\"{g['root_id']}G\")\n",
        "                    assigned = True\n",
        "                    break\n",
        "        if not assigned:\n",
        "            groups.append({\"name\": name, \"base_name\": base_name, \"root_id\": pid})\n",
        "            group_ids.append(f\"{pid}G\")\n",
        "        continue\n",
        "\n",
        "    # RULE 3: CHECK BASE NAME FIRST (for \"Name + Number\" pattern)\n",
        "    assigned = False\n",
        "\n",
        "    for g in groups:\n",
        "        if g[\"name\"] in [\"UNKNOWN\", \"NO_NAME\"]:\n",
        "            continue\n",
        "        if g[\"name\"].lower().startswith(\"pt perkebunan nusantara\"):\n",
        "            continue\n",
        "\n",
        "        # Check if base names match exactly\n",
        "        if base_name == g[\"base_name\"] and base_name != name:\n",
        "            # Same base name (e.g., both \"Palong\") → group together!\n",
        "            group_ids.append(f\"{g['root_id']}G\")\n",
        "            assigned = True\n",
        "            break\n",
        "\n",
        "    if assigned:\n",
        "        continue\n",
        "\n",
        "    # RULE 4: NORMAL FUZZY GROUPING (if base name didn't match)\n",
        "    for g in groups:\n",
        "        if g[\"name\"] in [\"UNKNOWN\", \"NO_NAME\"]:\n",
        "            continue\n",
        "        if g[\"name\"].lower().startswith(\"pt perkebunan nusantara\"):\n",
        "            continue\n",
        "\n",
        "        sim = fuzz.token_sort_ratio(name, g[\"name\"])\n",
        "        if sim >= FUZZY_THRESHOLD:\n",
        "            group_ids.append(f\"{g['root_id']}G\")\n",
        "            assigned = True\n",
        "            break\n",
        "\n",
        "    if not assigned:\n",
        "        groups.append({\"name\": name, \"base_name\": base_name, \"root_id\": pid})\n",
        "        group_ids.append(f\"{pid}G\")\n",
        "\n",
        "df[\"GroupID\"] = group_ids\n",
        "\n",
        "print(f\"Step 1 complete: {len(groups)} name-based groups created\")\n",
        "\n",
        "# Show Palong grouping\n",
        "palong_df = df[df[\"base_name\"].str.contains(\"Palong\", na=False, case=False)]\n",
        "if len(palong_df) > 0:\n",
        "    print(\"\\nPalong plots grouping:\")\n",
        "    print(palong_df[[\"ID\", \"Name\", \"base_name\", \"GroupID\"]])\n",
        "\n",
        "# ======================================================\n",
        "# STEP 2: LOAD GEOMETRY & PROXIMITY REFINE\n",
        "# ======================================================\n",
        "gdf = gpd.read_file(GPKG_FILE)\n",
        "gdf[id_col] = gdf[id_col].astype(str)\n",
        "\n",
        "# Merge geometry\n",
        "merged = df.merge(gdf[[id_col, \"geometry\"]], on=id_col, how=\"left\")\n",
        "geo = gpd.GeoDataFrame(merged, geometry=\"geometry\")\n",
        "\n",
        "# Convert CRS & calculate centroids\n",
        "geo = geo.to_crs(3857)\n",
        "geo[\"centroid\"] = geo.geometry.centroid\n",
        "\n",
        "# ======================================================\n",
        "# PROXIMITY REFINE (ONLY FOR ELIGIBLE GROUPS)\n",
        "# ======================================================\n",
        "refined_group = []\n",
        "\n",
        "for group_id, sub in geo.groupby(\"GroupID\"):\n",
        "\n",
        "    # Skip solo plots\n",
        "    if len(sub) == 1:\n",
        "        refined_group.append((sub.index[0], group_id))\n",
        "        continue\n",
        "\n",
        "    # Check if UNKNOWN/NO_NAME group\n",
        "    names = sub[name_col].unique()\n",
        "    if len(names) == 1 and names[0] in [\"UNKNOWN\", \"NO_NAME\"]:\n",
        "        for idx, pid in zip(sub.index, sub[id_col]):\n",
        "            refined_group.append((idx, f\"{pid}G\"))\n",
        "        continue\n",
        "\n",
        "    # Normal proximity refinement\n",
        "    ids = sub[id_col].tolist()\n",
        "    cents = sub[\"centroid\"].tolist()\n",
        "    indices = sub.index.tolist()\n",
        "    n = len(ids)\n",
        "\n",
        "    # Build adjacency matrix\n",
        "    adj = []\n",
        "    for i in range(n):\n",
        "        row = []\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                row.append(1)\n",
        "            else:\n",
        "                d = dist_km(cents[i], cents[j])\n",
        "                row.append(1 if d <= MAX_DIST_KM else 0)\n",
        "        adj.append(row)\n",
        "\n",
        "    # Find connected components\n",
        "    graph = csr_matrix(adj)\n",
        "    n_components, labels = connected_components(graph, directed=False)\n",
        "\n",
        "    if n_components == 1:\n",
        "        # All connected → keep original GroupID\n",
        "        for idx in indices:\n",
        "            refined_group.append((idx, group_id))\n",
        "    else:\n",
        "        # Split into sub-groups\n",
        "        for comp_id in range(n_components):\n",
        "            comp_indices = [indices[i] for i in range(n) if labels[i] == comp_id]\n",
        "\n",
        "            if len(comp_indices) == 1:\n",
        "                idx = comp_indices[0]\n",
        "                pid = geo.loc[idx, id_col]\n",
        "                refined_group.append((idx, f\"{pid}G\"))\n",
        "            else:\n",
        "                first_id = geo.loc[comp_indices[0], id_col]\n",
        "                new_group = f\"{first_id}G\"\n",
        "                for idx in comp_indices:\n",
        "                    refined_group.append((idx, new_group))\n",
        "\n",
        "# Assign final groups\n",
        "idx_map = {i: g for i, g in refined_group}\n",
        "geo[\"GroupID_proximity\"] = geo.index.map(idx_map)\n",
        "\n",
        "print(f\"\\nStep 2 complete: Proximity refinement done\")\n",
        "\n",
        "# ======================================================\n",
        "# STATISTICS & SAVE\n",
        "# ======================================================\n",
        "result = geo.drop(columns=[\"geometry\", \"centroid\"])\n",
        "\n",
        "# Stats\n",
        "group_sizes = result.groupby(\"GroupID_proximity\").size()\n",
        "print(f\"\\nFinal statistics:\")\n",
        "print(f\"  Total plots: {len(result)}\")\n",
        "print(f\"  Solo plots: {(group_sizes == 1).sum()}\")\n",
        "print(f\"  Groups with 2+ plots: {(group_sizes > 1).sum()}\")\n",
        "print(f\"  Largest group: {group_sizes.max()} plots\")\n",
        "\n",
        "# Show Palong final result\n",
        "palong_result = result[result[\"base_name\"].str.contains(\"Palong\", na=False, case=False)]\n",
        "if len(palong_result) > 0:\n",
        "    print(\"\\nPalong plots FINAL:\")\n",
        "    print(palong_result[[\"ID\", \"Name\", \"GroupID\", \"GroupID_proximity\"]])\n",
        "\n",
        "# Save\n",
        "result.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"\\nSaved: {OUTPUT_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTJIXx0TWpEh",
        "outputId": "dd7fb547-e564-4d91-d320-85b931ed7e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 complete: 7119 name-based groups created\n",
            "\n",
            "Palong plots grouping:\n",
            "         ID                                               Name  \\\n",
            "4609   9033                        FGVPM Palong Timur 5 Estate   \n",
            "4625   9049                                      Palong Estate   \n",
            "5712  10136                                     Palong Timur 3   \n",
            "5713  10137                        FGVPM Palong Timur 6 Estate   \n",
            "5714  10138                                     Palong Timur 1   \n",
            "5716  10140                                     Palong Timur 2   \n",
            "5727  10151                                           Palong 3   \n",
            "5949  10375                                           Palong 4   \n",
            "5950  10376                                           Palong 6   \n",
            "5951  10377                                           Palong 2   \n",
            "5952  10378                                           Palong 1   \n",
            "5954  10380  Lee Brothers Plantation & Realty (M) Sdn Bhd (...   \n",
            "5965  10391                                    FGVPM Palong 17   \n",
            "5966  10392                              Ladang RISDA Palong 1   \n",
            "5967  10393                                    FGVPM Palong 20   \n",
            "5968  10394                              Ladang RISDA Palong 2   \n",
            "\n",
            "                                              base_name GroupID  \n",
            "4609                        FGVPM Palong Timur 5 Estate   9033G  \n",
            "4625                                      Palong Estate   9049G  \n",
            "5712                                       Palong Timur  10136G  \n",
            "5713                        FGVPM Palong Timur 6 Estate   9033G  \n",
            "5714                                       Palong Timur  10136G  \n",
            "5716                                       Palong Timur  10136G  \n",
            "5727                                             Palong  10151G  \n",
            "5949                                             Palong  10151G  \n",
            "5950                                             Palong  10151G  \n",
            "5951                                             Palong  10151G  \n",
            "5952                                             Palong  10151G  \n",
            "5954  Lee Brothers Plantation & Realty (M) Sdn Bhd (...  10380G  \n",
            "5965                                       FGVPM Palong  10391G  \n",
            "5966                                Ladang RISDA Palong  10392G  \n",
            "5967                                       FGVPM Palong  10391G  \n",
            "5968                                Ladang RISDA Palong  10392G  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyogrio/raw.py:198: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured 3D MultiPolygon' is converted to 'MultiPolygon Z'\n",
            "  return ogr_read(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 2 complete: Proximity refinement done\n",
            "\n",
            "Final statistics:\n",
            "  Total plots: 10758\n",
            "  Solo plots: 7835\n",
            "  Groups with 2+ plots: 958\n",
            "  Largest group: 54 plots\n",
            "\n",
            "Palong plots FINAL:\n",
            "         ID                                               Name GroupID  \\\n",
            "4609   9033                        FGVPM Palong Timur 5 Estate   9033G   \n",
            "4625   9049                                      Palong Estate   9049G   \n",
            "5712  10136                                     Palong Timur 3  10136G   \n",
            "5713  10137                        FGVPM Palong Timur 6 Estate   9033G   \n",
            "5714  10138                                     Palong Timur 1  10136G   \n",
            "5716  10140                                     Palong Timur 2  10136G   \n",
            "5727  10151                                           Palong 3  10151G   \n",
            "5949  10375                                           Palong 4  10151G   \n",
            "5950  10376                                           Palong 6  10151G   \n",
            "5951  10377                                           Palong 2  10151G   \n",
            "5952  10378                                           Palong 1  10151G   \n",
            "5954  10380  Lee Brothers Plantation & Realty (M) Sdn Bhd (...  10380G   \n",
            "5965  10391                                    FGVPM Palong 17  10391G   \n",
            "5966  10392                              Ladang RISDA Palong 1  10392G   \n",
            "5967  10393                                    FGVPM Palong 20  10391G   \n",
            "5968  10394                              Ladang RISDA Palong 2  10392G   \n",
            "\n",
            "     GroupID_proximity  \n",
            "4609             9033G  \n",
            "4625             9049G  \n",
            "5712            10136G  \n",
            "5713             9033G  \n",
            "5714            10136G  \n",
            "5716            10136G  \n",
            "5727            10151G  \n",
            "5949            10151G  \n",
            "5950            10151G  \n",
            "5951            10151G  \n",
            "5952            10151G  \n",
            "5954            10380G  \n",
            "5965            10391G  \n",
            "5966            10392G  \n",
            "5967            10391G  \n",
            "5968            10392G  \n",
            "\n",
            "Saved: Concessions-with-group-proximity.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **C. COMBINE PLOT GROUP AND PLOT GRIEVANCES**\n",
        "\n",
        "-lookup group name and groupid plot and mill"
      ],
      "metadata": {
        "id": "U_IsOpmBWvmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL MERGED WITH PLOT GROUP AND MILL GROUP LOOKUP."
      ],
      "metadata": {
        "id": "4TdKCMS9t7W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# ============================\n",
        "# Load Files\n",
        "# ============================\n",
        "mhg = pd.read_csv(\"MHG_Newest_fixx.csv\", dtype=str).fillna(\"\")\n",
        "plot = pd.read_csv(\"Concessions-with-group-proximity.csv\", dtype=str).fillna(\"\")\n",
        "mill = pd.read_csv(\"Mills-Grid view (10).csv\", dtype=str).fillna(\"\")\n",
        "\n",
        "# ============================\n",
        "# Helper: Ambil angka sebelum \"_\"\n",
        "# ============================\n",
        "def extract_id(x):\n",
        "    if pd.isna(x):\n",
        "        return \"\"\n",
        "    # PO100… adalah Mill ID\n",
        "    if x.startswith(\"PO100\"):\n",
        "        m = re.match(r\"(PO\\d+)_\", x)\n",
        "        if m:\n",
        "            return m.group(1)\n",
        "        return x\n",
        "    # Angka biasa adalah Plot ID\n",
        "    m = re.match(r\"(\\d+)_\", x)\n",
        "    if m:\n",
        "        return m.group(1)\n",
        "    return x\n",
        "\n",
        "mhg[\"BaseID\"] = mhg[\"MHGID\"].apply(extract_id)\n",
        "mhg[\"is_mill\"] = mhg[\"MHGID\"].apply(lambda x: x.startswith(\"PO100\"))\n",
        "\n",
        "# ============================\n",
        "# Build mapping from PLOT file\n",
        "# ============================\n",
        "plot[\"ID_clean\"] = plot[\"ID\"].apply(\n",
        "    lambda x: re.match(r\"(\\d+)\", x).group(1) if re.match(r\"(\\d+)\", x) else x\n",
        ")\n",
        "\n",
        "plot_group_map = plot.set_index(\"ID_clean\")[\"GroupID_proximity\"].to_dict()\n",
        "plot_group_name_map = plot.set_index(\"ID_clean\")[\"Group Name\"].to_dict()\n",
        "plot_group_airtable_map = plot.set_index(\"ID_clean\")[\"GroupAirtableRecID\"].to_dict()\n",
        "\n",
        "# Build reverse mapping: GroupID_proximity → list of all plot IDs in that group\n",
        "group_to_plots = {}\n",
        "for idx, row in plot.iterrows():\n",
        "    grp = row[\"GroupID_proximity\"]\n",
        "    pid = row[\"ID_clean\"]\n",
        "    if grp not in group_to_plots:\n",
        "        group_to_plots[grp] = []\n",
        "    group_to_plots[grp].append(pid)\n",
        "\n",
        "# ============================\n",
        "# Build mapping from MILL file\n",
        "# ============================\n",
        "mill[\"UML_ID_clean\"] = mill[\"UML_ID\"].apply(\n",
        "    lambda x: re.match(r\"(PO\\d+)\", x).group(1) if re.match(r\"(PO\\d+)\", x) else x\n",
        ")\n",
        "\n",
        "mill_group_name_map = mill.set_index(\"UML_ID_clean\")[\"Group_Name\"].to_dict()\n",
        "mill_group_airtable_map = mill.set_index(\"UML_ID_clean\")[\"GroupAirtableRecID\"].to_dict()\n",
        "\n",
        "# ============================\n",
        "# Determine GroupID_proximity per base ID\n",
        "# ============================\n",
        "def get_group_id(row):\n",
        "    if row[\"is_mill\"]:\n",
        "        return \"\"  # Mills don't have GroupID_proximity\n",
        "    else:\n",
        "        return plot_group_map.get(row[\"BaseID\"], \"\")\n",
        "\n",
        "mhg[\"GroupID_proximity\"] = mhg.apply(get_group_id, axis=1)\n",
        "\n",
        "# ============================\n",
        "# Issue group from suffix\n",
        "# ============================\n",
        "mhg[\"issue_group\"] = mhg[\"MHGID\"].apply(\n",
        "    lambda x: x.split(\"_\")[1] if \"_\" in x else \"\"\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# Build grouping dict\n",
        "# ============================\n",
        "group_dict = {}\n",
        "\n",
        "for idx, row in mhg.iterrows():\n",
        "    base = row[\"BaseID\"]\n",
        "    grp = row[\"GroupID_proximity\"]\n",
        "    issue = row[\"issue_group\"]\n",
        "    is_mill = row[\"is_mill\"]\n",
        "\n",
        "    if is_mill:\n",
        "        # Mills: No merge with others, each is unique\n",
        "        group_key = f\"MILL-{row['MHGID']}\"\n",
        "    elif grp == \"\":\n",
        "        # No group found\n",
        "        group_key = f\"{base}-{issue}\"\n",
        "    else:\n",
        "        # Normal plot grouping\n",
        "        group_key = f\"{grp}-{issue}\"\n",
        "\n",
        "    group_dict.setdefault(group_key, []).append(idx)\n",
        "\n",
        "# ============================\n",
        "# Merge Process\n",
        "# ============================\n",
        "merged_rows = []\n",
        "merge_count = 0\n",
        "\n",
        "cols_to_merge = [\n",
        "    c for c in mhg.columns\n",
        "    if c not in [\"MHGID\", \"BaseID\", \"GroupID_proximity\", \"issue_group\", \"is_mill\"]\n",
        "]\n",
        "\n",
        "for group_key, indices in group_dict.items():\n",
        "\n",
        "    # only 1 → no merge\n",
        "    if len(indices) == 1:\n",
        "        row = mhg.loc[indices[0]].copy()\n",
        "        base = row[\"BaseID\"]\n",
        "        is_mill = row[\"is_mill\"]\n",
        "\n",
        "        if is_mill:\n",
        "            # Mill lookup\n",
        "            row[\"Group Name\"] = mill_group_name_map.get(base, \"\")\n",
        "            row[\"GroupAirtableRecID\"] = mill_group_airtable_map.get(base, \"\")\n",
        "            row[\"Plot_group\"] = \"\"  # Mills don't have plot groups\n",
        "        else:\n",
        "            # Plot lookup\n",
        "            row[\"Group Name\"] = plot_group_name_map.get(base, \"\")\n",
        "            row[\"GroupAirtableRecID\"] = plot_group_airtable_map.get(base, \"\")\n",
        "\n",
        "            # Expand plot_group: get ALL plots in this GroupID_proximity\n",
        "            grp = row[\"GroupID_proximity\"]\n",
        "            if grp and grp in group_to_plots:\n",
        "                row[\"Plot_group\"] = \", \".join(sorted(group_to_plots[grp]))\n",
        "            else:\n",
        "                row[\"Plot_group\"] = base\n",
        "\n",
        "        merged_rows.append(row.to_dict())\n",
        "        continue\n",
        "\n",
        "    # merge happens\n",
        "    merge_count += (len(indices) - 1)\n",
        "    df = mhg.loc[indices]\n",
        "\n",
        "    rep = df.iloc[0].copy()\n",
        "    rep_base = rep[\"BaseID\"]\n",
        "    is_mill = rep[\"is_mill\"]\n",
        "\n",
        "    # merge unique values\n",
        "    for col in cols_to_merge:\n",
        "        vals = df[col].tolist()\n",
        "        uniq = sorted(set(sum([\n",
        "            v.split(\", \") if \", \" in v else [v] for v in vals\n",
        "        ], [])))\n",
        "        uniq = [v for v in uniq if v != \"\"]\n",
        "        rep[col] = \", \".join(uniq)\n",
        "\n",
        "    if is_mill:\n",
        "        # Mill lookup\n",
        "        rep[\"Group Name\"] = mill_group_name_map.get(rep_base, \"\")\n",
        "        rep[\"GroupAirtableRecID\"] = mill_group_airtable_map.get(rep_base, \"\")\n",
        "        rep[\"Plot_group\"] = \"\"  # Mills don't have plot groups\n",
        "    else:\n",
        "        # Plot lookup\n",
        "        rep[\"Group Name\"] = plot_group_name_map.get(rep_base, \"\")\n",
        "        rep[\"GroupAirtableRecID\"] = plot_group_airtable_map.get(rep_base, \"\")\n",
        "\n",
        "        # Expand plot_group: get ALL plots in this GroupID_proximity\n",
        "        grp = rep[\"GroupID_proximity\"]\n",
        "        if grp and grp in group_to_plots:\n",
        "            rep[\"Plot_group\"] = \", \".join(sorted(group_to_plots[grp]))\n",
        "        else:\n",
        "            # Fallback: use BaseIDs from merged rows\n",
        "            plot_ids = sorted(set(df[\"BaseID\"].tolist()))\n",
        "            rep[\"Plot_group\"] = \", \".join(plot_ids)\n",
        "\n",
        "    # recalc grievance_count from updated grievance_IDs\n",
        "    if \"grievance_IDs\" in rep:\n",
        "        gid_list = rep[\"grievance_IDs\"].split(\", \")\n",
        "        gid_list = [x for x in gid_list if x != \"\"]\n",
        "        rep[\"grievance_count\"] = str(len(set(gid_list)))\n",
        "\n",
        "    merged_rows.append(rep.to_dict())\n",
        "\n",
        "# ============================\n",
        "# Build final DF\n",
        "# ============================\n",
        "result = pd.DataFrame(merged_rows)\n",
        "\n",
        "# Drop helper columns from output\n",
        "result = result.drop(columns=[\"BaseID\", \"issue_group\", \"is_mill\"], errors=\"ignore\")\n",
        "\n",
        "print(\"Jumlah sebelum merge :\", len(mhg))\n",
        "print(\"Jumlah sesudah merge :\", len(result))\n",
        "print(\"Total rows merged    :\", merge_count)\n",
        "\n",
        "# Show sample of mills\n",
        "mill_results = result[result[\"MHGID\"].str.startswith(\"PO100\", na=False)]\n",
        "if len(mill_results) > 0:\n",
        "    print(\"\\nSample Mill results:\")\n",
        "    print(mill_results[[\"MHGID\", \"Group Name\", \"GroupAirtableRecID\"]].head())\n",
        "\n",
        "# Show sample of plots with expanded plot_group\n",
        "plot_results = result[~result[\"MHGID\"].str.startswith(\"PO100\", na=False)]\n",
        "if len(plot_results) > 0:\n",
        "    print(\"\\nSample Plot results with expanded Plot_group:\")\n",
        "    print(plot_results[[\"MHGID\", \"Plot_group\", \"Group Name\"]].head())\n",
        "\n",
        "# ============================\n",
        "# Export\n",
        "# ============================\n",
        "result.to_csv(\"MHG_Merged_Final.csv\", index=False)\n",
        "print(\"\\nFile saved as MHG_Merged_Final.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEhMqqlrt2bj",
        "outputId": "29705769-a0d1-4f16-e7d9-226043fe174a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah sebelum merge : 1293\n",
            "Jumlah sesudah merge : 1053\n",
            "Total rows merged    : 240\n",
            "\n",
            "Sample Mill results:\n",
            "                MHGID       Group Name GroupAirtableRecID\n",
            "716  PO1000000017_soc        AGROPALMA  recNkyyeESIxx6zeL\n",
            "717  PO1000000099_env            SIPEF  rec440HVR0OrBALic\n",
            "718  PO1000000099_soc            SIPEF  rec440HVR0OrBALic\n",
            "719  PO1000000109_env  IOI CORPORATION  recJ3cFKfD2UMrzZg\n",
            "720  PO1000000109_soc  IOI CORPORATION  recJ3cFKfD2UMrzZg\n",
            "\n",
            "Sample Plot results with expanded Plot_group:\n",
            "       MHGID           Plot_group               Group Name\n",
            "0  10060_env                10060          YPJ PLANTATIONS\n",
            "1  10136_env  10136, 10138, 10140                    FELDA\n",
            "2  10137_env          10137, 9033                      FGV\n",
            "3  10289_env                10289  Ladang Rakyat Trengganu\n",
            "4  10681_env                10681             Puncak Niaga\n",
            "\n",
            "File saved as MHG_Merged_Final.csv\n"
          ]
        }
      ]
    }
  ]
}