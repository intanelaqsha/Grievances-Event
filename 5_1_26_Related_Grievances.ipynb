{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsVZJAZBr52mdn70dL6yG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/intanelaqsha/Grievances-Event/blob/main/5_1_26_Related_Grievances.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A. SCENARIO C STEP 1**\n",
        "\n",
        "calling all plot/mill mentioned in the grievances."
      ],
      "metadata": {
        "id": "r8H46W-KWE0V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iUIlkjgN2sj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"Grievances-Grid view.csv\", dtype=str).fillna(\"\")\n",
        "\n",
        "# -------------------------\n",
        "# Step 1: Load & normalize\n",
        "# -------------------------\n",
        "\n",
        "def clean_array(x):\n",
        "    if x.strip() == \"\":\n",
        "        return []\n",
        "    return list(dict.fromkeys([i for i in x.split(\",\") if i.strip() != \"\"]))\n",
        "\n",
        "df[\"plots_array\"] = df[\"PIOConcessions-v2\"].apply(lambda s: clean_array(s.replace(\" \", \"\")))\n",
        "df[\"mills_array\"] = df[\"Mills\"].apply(lambda s: clean_array(s.replace(\" \", \"\")))\n",
        "\n",
        "# Source: reproduce DuckDB logic exactly\n",
        "def split_source(src):\n",
        "    if src.strip() == \"\":\n",
        "        return []\n",
        "    tmp = src.replace(\", \", \"<COMMA_SPACE>\")\n",
        "    parts = tmp.split(\",\")\n",
        "    cleaned = [p.strip().replace(\"<COMMA_SPACE>\", \", \") for p in parts if p.strip() != \"\"]\n",
        "    return list(dict.fromkeys(cleaned))\n",
        "\n",
        "df[\"source_array\"] = df[\"Source\"].apply(split_source)\n",
        "\n",
        "df[\"issues_array\"] = df[\"Issues\"].apply(\n",
        "    lambda s: list(dict.fromkeys([i.strip() for i in s.split(\",\") if i.strip() != \"\"]))\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Step 2: Unnest arrays\n",
        "# -------------------------\n",
        "\n",
        "g_plots = df.explode(\"plots_array\")[[\"ID\", \"plots_array\"]].rename(columns={\"plots_array\": \"plot\"})\n",
        "g_mills = df.explode(\"mills_array\")[[\"ID\", \"mills_array\"]].rename(columns={\"mills_array\": \"mill\"})\n",
        "g_issues = df.explode(\"issues_array\")[[\"ID\", \"issues_array\"]].rename(columns={\"issues_array\": \"issue\"})\n",
        "\n",
        "# -------------------------\n",
        "# Step 3: issue category\n",
        "# -------------------------\n",
        "\n",
        "issue_category = pd.DataFrame([\n",
        "    ('Biodiversity loss', 'ENV'), ('Deforestation', 'ENV'), ('Fires', 'ENV'),\n",
        "    ('Illegal Infrastructure', 'ENV'), ('Infrastructure Damage', 'ENV'),\n",
        "    ('Peatland Loss', 'ENV'), ('Riparian Issues', 'ENV'), ('Environmental Pollution', 'ENV'),\n",
        "    ('Corruption', 'SOC'), ('Forced Labor and/or Child Labor', 'SOC'),\n",
        "    ('Gender and Ethnic Disparities', 'SOC'), ('Human Rights Violation', 'SOC'),\n",
        "    ('Indigenous Peoples Conflict', 'SOC'), ('Labor Rights Violations', 'SOC'),\n",
        "    ('Land Dispute', 'SOC'), ('Land Grabbing', 'SOC'), ('Labor Disputes', 'SOC'),\n",
        "    ('Limited Access to Services', 'SOC'), ('Violence and/or Coercion', 'SOC'),\n",
        "    ('Wage Dispute', 'SOC')\n",
        "], columns=[\"issue\", \"category\"])\n",
        "\n",
        "# -------------------------\n",
        "# Step 4: generate group_key\n",
        "# -------------------------\n",
        "\n",
        "plot_issue = g_plots.merge(g_issues, on=\"ID\", how=\"inner\") \\\n",
        "    .merge(issue_category, on=\"issue\", how=\"left\")\n",
        "\n",
        "plot_issue[\"group_key\"] = plot_issue[\"plot\"] + \"_\" + plot_issue[\"category\"].str.lower()\n",
        "\n",
        "mill_issue = g_mills.merge(g_issues, on=\"ID\", how=\"inner\") \\\n",
        "    .merge(issue_category, on=\"issue\", how=\"left\")\n",
        "\n",
        "mill_issue[\"group_key\"] = mill_issue[\"mill\"] + \"_\" + mill_issue[\"category\"].str.lower()\n",
        "\n",
        "# -------------------------\n",
        "# Step 5: union\n",
        "# -------------------------\n",
        "\n",
        "combined = pd.concat([\n",
        "    plot_issue[[\"group_key\", \"ID\"]],\n",
        "    mill_issue[[\"group_key\", \"ID\"]]\n",
        "], ignore_index=True)\n",
        "\n",
        "# -------------------------\n",
        "# Step 6: aggregation\n",
        "# -------------------------\n",
        "\n",
        "def flat_unique(series):\n",
        "    out = []\n",
        "    for arr in series:\n",
        "        if isinstance(arr, list):\n",
        "            out.extend(arr)\n",
        "    return list(dict.fromkeys(out))\n",
        "\n",
        "result = (\n",
        "    combined.merge(df, on=\"ID\", how=\"left\")\n",
        "    .groupby(\"group_key\")\n",
        "    .agg({\n",
        "        \"ID\": lambda x: sorted(set(x), key=lambda v: v),   # LIST(DISTINCT ID ORDER BY ID)\n",
        "        \"plots_array\": flat_unique,\n",
        "        \"mills_array\": flat_unique,\n",
        "        \"source_array\": flat_unique,\n",
        "        \"issues_array\": flat_unique,\n",
        "    })\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "result.rename(columns={\"group_key\": \"MHGID\"}, inplace=True)\n",
        "\n",
        "# -------------------------\n",
        "# Step 7: format output\n",
        "# -------------------------\n",
        "\n",
        "def fmt(x):\n",
        "    if isinstance(x, list):\n",
        "        if len(x) == 0:\n",
        "            return \"\"\n",
        "        return \", \".join(str(i) for i in x)\n",
        "    return x\n",
        "\n",
        "for col in [\"ID\", \"plots_array\", \"mills_array\", \"source_array\", \"issues_array\"]:\n",
        "    result[col] = result[col].apply(fmt)\n",
        "\n",
        "result.rename(columns={\n",
        "    \"ID\": \"grievance_IDs\",\n",
        "    \"plots_array\": \"plots\",\n",
        "    \"mills_array\": \"mills\",\n",
        "    \"source_array\": \"sources\",\n",
        "    \"issues_array\": \"issues\"\n",
        "}, inplace=True)\n",
        "\n",
        "# -------------------------\n",
        "# NEW: grievance_count\n",
        "# -------------------------\n",
        "result[\"grievance_count\"] = result[\"grievance_IDs\"].apply(\n",
        "    lambda s: 0 if s == \"\" else len([i.strip() for i in s.split(\",\")])\n",
        ")\n",
        "\n",
        "result.to_csv(\"MHG_Newest_fix.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **B. GROUPING PLOT BY NAME SIMILARITY AND AREA PROXIMITY**"
      ],
      "metadata": {
        "id": "Z8gDV-4fWSPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- if name similar and under proximity, grouping"
      ],
      "metadata": {
        "id": "uDYUwOcabDKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LpmSSnyQSTZ",
        "outputId": "39dbc677-decf-4874-890f-b1e56811dfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.2 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# COMBINED STEP 1 & 2: NAME GROUPING + PROXIMITY REFINE\n",
        "# ======================================================\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from rapidfuzz import fuzz\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "import re\n",
        "\n",
        "# ======================================================\n",
        "# CONFIG\n",
        "# ======================================================\n",
        "INPUT_FILE = \"Concessions-v2-Grid view.csv\"\n",
        "GPKG_FILE = \"plots_v2_20251209.gpkg\"\n",
        "OUTPUT_FILE = \"Concessions-with-group-proximity.csv\"\n",
        "\n",
        "FUZZY_THRESHOLD = 90\n",
        "MAX_DIST_KM = 50\n",
        "\n",
        "name_col = \"Name\"\n",
        "id_col = \"ID\"\n",
        "\n",
        "# ======================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ======================================================\n",
        "\n",
        "def clean_id(x):\n",
        "    if pd.isna(x):\n",
        "        return \"UNKNOWN_ID\"\n",
        "    try:\n",
        "        return str(int(float(x)))\n",
        "    except:\n",
        "        return str(x).strip()\n",
        "\n",
        "def normalize_name(x):\n",
        "    if pd.isna(x):\n",
        "        return \"UNKNOWN\"\n",
        "    s = str(x).strip()\n",
        "    if s == \"\":\n",
        "        return \"UNKNOWN\"\n",
        "    if s.lower() == \"unknown\":\n",
        "        return \"UNKNOWN\"\n",
        "    if s.lower().startswith(\"no name\"):\n",
        "        return \"NO_NAME\"\n",
        "    return s\n",
        "\n",
        "def word_difference(a, b):\n",
        "    words_a = a.split()\n",
        "    words_b = b.split()\n",
        "    return len(set(words_a) ^ set(words_b))\n",
        "\n",
        "def extract_base_name(name):\n",
        "    \"\"\"\n",
        "    Extract base name without trailing numbers\n",
        "    'Palong 4' -> 'Palong'\n",
        "    'Estate A 12' -> 'Estate A'\n",
        "    'FELDA Bukit Jalor 1' -> 'FELDA Bukit Jalor'\n",
        "    \"\"\"\n",
        "    # Remove trailing numbers (with optional separators)\n",
        "    base = re.sub(r'\\s+\\d+$', '', name)\n",
        "    return base.strip()\n",
        "\n",
        "def dist_km(a, b):\n",
        "    return a.distance(b) / 1000.0\n",
        "\n",
        "# ======================================================\n",
        "# STEP 1: LOAD & NAME GROUPING\n",
        "# ======================================================\n",
        "df = pd.read_csv(INPUT_FILE)\n",
        "\n",
        "df[id_col] = df[id_col].apply(clean_id)\n",
        "df[name_col] = df[name_col].apply(normalize_name)\n",
        "\n",
        "# Extract base names for comparison\n",
        "df[\"base_name\"] = df[name_col].apply(extract_base_name)\n",
        "\n",
        "# Grouping by name\n",
        "groups = []\n",
        "group_ids = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    name = row[name_col]\n",
        "    base_name = row[\"base_name\"]\n",
        "    pid = row[id_col]\n",
        "\n",
        "    # RULE 1: UNKNOWN or NO NAME → own group\n",
        "    if name == \"UNKNOWN\" or name == \"NO_NAME\":\n",
        "        group_ids.append(f\"{pid}G\")\n",
        "        continue\n",
        "\n",
        "    # RULE 2: PT Perkebunan Nusantara → exact match only\n",
        "    if name.lower().startswith(\"pt perkebunan nusantara\"):\n",
        "        assigned = False\n",
        "        for g in groups:\n",
        "            if g[\"name\"].lower().startswith(\"pt perkebunan nusantara\"):\n",
        "                if word_difference(name, g[\"name\"]) == 0:\n",
        "                    group_ids.append(f\"{g['root_id']}G\")\n",
        "                    assigned = True\n",
        "                    break\n",
        "        if not assigned:\n",
        "            groups.append({\"name\": name, \"base_name\": base_name, \"root_id\": pid})\n",
        "            group_ids.append(f\"{pid}G\")\n",
        "        continue\n",
        "\n",
        "    # RULE 3: CHECK BASE NAME FIRST (for \"Name + Number\" pattern)\n",
        "    assigned = False\n",
        "\n",
        "    for g in groups:\n",
        "        if g[\"name\"] in [\"UNKNOWN\", \"NO_NAME\"]:\n",
        "            continue\n",
        "        if g[\"name\"].lower().startswith(\"pt perkebunan nusantara\"):\n",
        "            continue\n",
        "\n",
        "        # Check if base names match exactly\n",
        "        if base_name == g[\"base_name\"] and base_name != name:\n",
        "            # Same base name (e.g., both \"Palong\") → group together!\n",
        "            group_ids.append(f\"{g['root_id']}G\")\n",
        "            assigned = True\n",
        "            break\n",
        "\n",
        "    if assigned:\n",
        "        continue\n",
        "\n",
        "    # RULE 4: NORMAL FUZZY GROUPING (if base name didn't match)\n",
        "    for g in groups:\n",
        "        if g[\"name\"] in [\"UNKNOWN\", \"NO_NAME\"]:\n",
        "            continue\n",
        "        if g[\"name\"].lower().startswith(\"pt perkebunan nusantara\"):\n",
        "            continue\n",
        "\n",
        "        sim = fuzz.token_sort_ratio(name, g[\"name\"])\n",
        "        if sim >= FUZZY_THRESHOLD:\n",
        "            group_ids.append(f\"{g['root_id']}G\")\n",
        "            assigned = True\n",
        "            break\n",
        "\n",
        "    if not assigned:\n",
        "        groups.append({\"name\": name, \"base_name\": base_name, \"root_id\": pid})\n",
        "        group_ids.append(f\"{pid}G\")\n",
        "\n",
        "df[\"GroupID\"] = group_ids\n",
        "\n",
        "print(f\"Step 1 complete: {len(groups)} name-based groups created\")\n",
        "\n",
        "# Show Palong grouping\n",
        "palong_df = df[df[\"base_name\"].str.contains(\"Palong\", na=False, case=False)]\n",
        "if len(palong_df) > 0:\n",
        "    print(\"\\nPalong plots grouping:\")\n",
        "    print(palong_df[[\"ID\", \"Name\", \"base_name\", \"GroupID\"]])\n",
        "\n",
        "# ======================================================\n",
        "# STEP 2: LOAD GEOMETRY & PROXIMITY REFINE\n",
        "# ======================================================\n",
        "gdf = gpd.read_file(GPKG_FILE)\n",
        "gdf[id_col] = gdf[id_col].astype(str)\n",
        "\n",
        "# Merge geometry\n",
        "merged = df.merge(gdf[[id_col, \"geometry\"]], on=id_col, how=\"left\")\n",
        "geo = gpd.GeoDataFrame(merged, geometry=\"geometry\")\n",
        "\n",
        "# Convert CRS & calculate centroids\n",
        "geo = geo.to_crs(3857)\n",
        "geo[\"centroid\"] = geo.geometry.centroid\n",
        "\n",
        "# ======================================================\n",
        "# PROXIMITY REFINE (ONLY FOR ELIGIBLE GROUPS)\n",
        "# ======================================================\n",
        "refined_group = []\n",
        "\n",
        "for group_id, sub in geo.groupby(\"GroupID\"):\n",
        "\n",
        "    # Skip solo plots\n",
        "    if len(sub) == 1:\n",
        "        refined_group.append((sub.index[0], group_id))\n",
        "        continue\n",
        "\n",
        "    # Check if UNKNOWN/NO_NAME group\n",
        "    names = sub[name_col].unique()\n",
        "    if len(names) == 1 and names[0] in [\"UNKNOWN\", \"NO_NAME\"]:\n",
        "        for idx, pid in zip(sub.index, sub[id_col]):\n",
        "            refined_group.append((idx, f\"{pid}G\"))\n",
        "        continue\n",
        "\n",
        "    # Normal proximity refinement\n",
        "    ids = sub[id_col].tolist()\n",
        "    cents = sub[\"centroid\"].tolist()\n",
        "    indices = sub.index.tolist()\n",
        "    n = len(ids)\n",
        "\n",
        "    # Build adjacency matrix\n",
        "    adj = []\n",
        "    for i in range(n):\n",
        "        row = []\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                row.append(1)\n",
        "            else:\n",
        "                d = dist_km(cents[i], cents[j])\n",
        "                row.append(1 if d <= MAX_DIST_KM else 0)\n",
        "        adj.append(row)\n",
        "\n",
        "    # Find connected components\n",
        "    graph = csr_matrix(adj)\n",
        "    n_components, labels = connected_components(graph, directed=False)\n",
        "\n",
        "    if n_components == 1:\n",
        "        # All connected → keep original GroupID\n",
        "        for idx in indices:\n",
        "            refined_group.append((idx, group_id))\n",
        "    else:\n",
        "        # Split into sub-groups\n",
        "        for comp_id in range(n_components):\n",
        "            comp_indices = [indices[i] for i in range(n) if labels[i] == comp_id]\n",
        "\n",
        "            if len(comp_indices) == 1:\n",
        "                idx = comp_indices[0]\n",
        "                pid = geo.loc[idx, id_col]\n",
        "                refined_group.append((idx, f\"{pid}G\"))\n",
        "            else:\n",
        "                first_id = geo.loc[comp_indices[0], id_col]\n",
        "                new_group = f\"{first_id}G\"\n",
        "                for idx in comp_indices:\n",
        "                    refined_group.append((idx, new_group))\n",
        "\n",
        "# Assign final groups\n",
        "idx_map = {i: g for i, g in refined_group}\n",
        "geo[\"GroupID_proximity\"] = geo.index.map(idx_map)\n",
        "\n",
        "print(f\"\\nStep 2 complete: Proximity refinement done\")\n",
        "\n",
        "# ======================================================\n",
        "# STATISTICS & SAVE\n",
        "# ======================================================\n",
        "result = geo.drop(columns=[\"geometry\", \"centroid\"])\n",
        "\n",
        "# Stats\n",
        "group_sizes = result.groupby(\"GroupID_proximity\").size()\n",
        "print(f\"\\nFinal statistics:\")\n",
        "print(f\"  Total plots: {len(result)}\")\n",
        "print(f\"  Solo plots: {(group_sizes == 1).sum()}\")\n",
        "print(f\"  Groups with 2+ plots: {(group_sizes > 1).sum()}\")\n",
        "print(f\"  Largest group: {group_sizes.max()} plots\")\n",
        "\n",
        "# Show Palong final result\n",
        "palong_result = result[result[\"base_name\"].str.contains(\"Palong\", na=False, case=False)]\n",
        "if len(palong_result) > 0:\n",
        "   # print(\"\\nPalong plots FINAL:\")\n",
        "    print(palong_result[[\"ID\", \"Name\", \"GroupID\", \"GroupID_proximity\"]])\n",
        "\n",
        "# Save\n",
        "result.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"\\nSaved: {OUTPUT_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTJIXx0TWpEh",
        "outputId": "dd3083b9-fb0d-4423-d907-cc5d91ce5a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 complete: 7120 name-based groups created\n",
            "\n",
            "Palong plots grouping:\n",
            "         ID                                               Name  \\\n",
            "4608   9033                        FGVPM Palong Timur 5 Estate   \n",
            "4624   9049                                      Palong Estate   \n",
            "5711  10136                                     Palong Timur 3   \n",
            "5712  10137                        FGVPM Palong Timur 6 Estate   \n",
            "5713  10138                                     Palong Timur 1   \n",
            "5715  10140                                     Palong Timur 2   \n",
            "5726  10151                                           Palong 3   \n",
            "5948  10375                                           Palong 4   \n",
            "5949  10376                                           Palong 6   \n",
            "5950  10377                                           Palong 2   \n",
            "5951  10378                                           Palong 1   \n",
            "5953  10380  Lee Brothers Plantation & Realty (M) Sdn Bhd (...   \n",
            "5964  10391                                    FGVPM Palong 17   \n",
            "5965  10392                              Ladang RISDA Palong 1   \n",
            "5966  10393                                    FGVPM Palong 20   \n",
            "5967  10394                              Ladang RISDA Palong 2   \n",
            "\n",
            "                                              base_name GroupID  \n",
            "4608                        FGVPM Palong Timur 5 Estate   9033G  \n",
            "4624                                      Palong Estate   9049G  \n",
            "5711                                       Palong Timur  10136G  \n",
            "5712                        FGVPM Palong Timur 6 Estate   9033G  \n",
            "5713                                       Palong Timur  10136G  \n",
            "5715                                       Palong Timur  10136G  \n",
            "5726                                             Palong  10151G  \n",
            "5948                                             Palong  10151G  \n",
            "5949                                             Palong  10151G  \n",
            "5950                                             Palong  10151G  \n",
            "5951                                             Palong  10151G  \n",
            "5953  Lee Brothers Plantation & Realty (M) Sdn Bhd (...  10380G  \n",
            "5964                                       FGVPM Palong  10391G  \n",
            "5965                                Ladang RISDA Palong  10392G  \n",
            "5966                                       FGVPM Palong  10391G  \n",
            "5967                                Ladang RISDA Palong  10392G  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyogrio/raw.py:200: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured 3D MultiPolygon' is converted to 'MultiPolygon Z'\n",
            "  return ogr_read(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 2 complete: Proximity refinement done\n",
            "\n",
            "Final statistics:\n",
            "  Total plots: 10759\n",
            "  Solo plots: 7836\n",
            "  Groups with 2+ plots: 958\n",
            "  Largest group: 54 plots\n",
            "         ID                                               Name GroupID  \\\n",
            "4608   9033                        FGVPM Palong Timur 5 Estate   9033G   \n",
            "4624   9049                                      Palong Estate   9049G   \n",
            "5711  10136                                     Palong Timur 3  10136G   \n",
            "5712  10137                        FGVPM Palong Timur 6 Estate   9033G   \n",
            "5713  10138                                     Palong Timur 1  10136G   \n",
            "5715  10140                                     Palong Timur 2  10136G   \n",
            "5726  10151                                           Palong 3  10151G   \n",
            "5948  10375                                           Palong 4  10151G   \n",
            "5949  10376                                           Palong 6  10151G   \n",
            "5950  10377                                           Palong 2  10151G   \n",
            "5951  10378                                           Palong 1  10151G   \n",
            "5953  10380  Lee Brothers Plantation & Realty (M) Sdn Bhd (...  10380G   \n",
            "5964  10391                                    FGVPM Palong 17  10391G   \n",
            "5965  10392                              Ladang RISDA Palong 1  10392G   \n",
            "5966  10393                                    FGVPM Palong 20  10391G   \n",
            "5967  10394                              Ladang RISDA Palong 2  10392G   \n",
            "\n",
            "     GroupID_proximity  \n",
            "4608             9033G  \n",
            "4624             9049G  \n",
            "5711            10136G  \n",
            "5712             9033G  \n",
            "5713            10136G  \n",
            "5715            10136G  \n",
            "5726            10151G  \n",
            "5948            10151G  \n",
            "5949            10151G  \n",
            "5950            10151G  \n",
            "5951            10151G  \n",
            "5953            10380G  \n",
            "5964            10391G  \n",
            "5965            10392G  \n",
            "5966            10391G  \n",
            "5967            10392G  \n",
            "\n",
            "Saved: Concessions-with-group-proximity.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **C. COMBINE GROUP NAME AND PLOT/MILL GRIEVANCES**\n",
        "\n",
        "-lookup group name"
      ],
      "metadata": {
        "id": "U_IsOpmBWvmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL MERGED WITH PLOT GROUP AND MILL GROUP LOOKUP."
      ],
      "metadata": {
        "id": "4TdKCMS9t7W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# ============================\n",
        "# Load Files\n",
        "# ============================\n",
        "mhg = pd.read_csv(\"MHG_Newest_fix.csv\", dtype=str).fillna(\"\")\n",
        "plot = pd.read_csv(\"Concessions-with-group-proximity.csv\", dtype=str).fillna(\"\")\n",
        "mill = pd.read_csv(\"Mills-Grid view.csv\", dtype=str).fillna(\"\")\n",
        "\n",
        "# ============================\n",
        "# Helper: Ambil angka sebelum \"_\"\n",
        "# ============================\n",
        "def extract_id(x):\n",
        "    if pd.isna(x):\n",
        "        return \"\"\n",
        "    # PO100… adalah Mill ID\n",
        "    if x.startswith(\"PO100\"):\n",
        "        m = re.match(r\"(PO\\d+)_\", x)\n",
        "        if m:\n",
        "            return m.group(1)\n",
        "        return x\n",
        "    # Angka biasa adalah Plot ID\n",
        "    m = re.match(r\"(\\d+)_\", x)\n",
        "    if m:\n",
        "        return m.group(1)\n",
        "    return x\n",
        "\n",
        "mhg[\"BaseID\"] = mhg[\"MHGID\"].apply(extract_id)\n",
        "mhg[\"is_mill\"] = mhg[\"MHGID\"].apply(lambda x: x.startswith(\"PO100\"))\n",
        "\n",
        "# ============================\n",
        "# Build mapping from PLOT file\n",
        "# ============================\n",
        "plot[\"ID_clean\"] = plot[\"ID\"].apply(\n",
        "    lambda x: re.match(r\"(\\d+)\", x).group(1) if re.match(r\"(\\d+)\", x) else x\n",
        ")\n",
        "\n",
        "plot_group_map = plot.set_index(\"ID_clean\")[\"GroupID_proximity\"].to_dict()\n",
        "plot_group_name_map = plot.set_index(\"ID_clean\")[\"Group Name\"].to_dict()\n",
        "plot_group_airtable_map = plot.set_index(\"ID_clean\")[\"GroupAirtableRecID\"].to_dict()\n",
        "plot_name_map = plot.set_index(\"ID_clean\")[\"Name\"].to_dict()\n",
        "\n",
        "# Build reverse mapping: GroupID_proximity → list of all plot IDs in that group\n",
        "group_to_plots = {}\n",
        "for idx, row in plot.iterrows():\n",
        "    grp = row[\"GroupID_proximity\"]\n",
        "    pid = row[\"ID_clean\"]\n",
        "    if grp not in group_to_plots:\n",
        "        group_to_plots[grp] = []\n",
        "    group_to_plots[grp].append(pid)\n",
        "\n",
        "# ============================\n",
        "# Build mapping from MILL file\n",
        "# ============================\n",
        "mill[\"UML_ID_clean\"] = mill[\"UML_ID\"].apply(\n",
        "    lambda x: re.match(r\"(PO\\d+)\", x).group(1) if re.match(r\"(PO\\d+)\", x) else x\n",
        ")\n",
        "\n",
        "mill_group_name_map = mill.set_index(\"UML_ID_clean\")[\"Group_Name\"].to_dict()\n",
        "mill_group_airtable_map = mill.set_index(\"UML_ID_clean\")[\"GroupAirtableRecID\"].to_dict()\n",
        "mill_name_map = mill.set_index(\"UML_ID_clean\")[\"Mill_Name\"].to_dict()\n",
        "\n",
        "# ============================\n",
        "# Determine GroupID_proximity per base ID\n",
        "# ============================\n",
        "def get_group_id(row):\n",
        "    if row[\"is_mill\"]:\n",
        "        return \"\"  # Mills don't have GroupID_proximity\n",
        "    else:\n",
        "        return plot_group_map.get(row[\"BaseID\"], \"\")\n",
        "\n",
        "mhg[\"GroupID_proximity\"] = mhg.apply(get_group_id, axis=1)\n",
        "\n",
        "# ============================\n",
        "# Issue group from suffix\n",
        "# ============================\n",
        "mhg[\"issue_group\"] = mhg[\"MHGID\"].apply(\n",
        "    lambda x: x.split(\"_\")[1] if \"_\" in x else \"\"\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# Build grouping dict\n",
        "# ============================\n",
        "group_dict = {}\n",
        "\n",
        "for idx, row in mhg.iterrows():\n",
        "    base = row[\"BaseID\"]\n",
        "    grp = row[\"GroupID_proximity\"]\n",
        "    issue = row[\"issue_group\"]\n",
        "    is_mill = row[\"is_mill\"]\n",
        "\n",
        "    if is_mill:\n",
        "        # Mills: No merge with others, each is unique\n",
        "        group_key = f\"MILL-{row['MHGID']}\"\n",
        "    elif grp == \"\":\n",
        "        # No group found\n",
        "        group_key = f\"{base}-{issue}\"\n",
        "    else:\n",
        "        # Normal plot grouping\n",
        "        group_key = f\"{grp}-{issue}\"\n",
        "\n",
        "    group_dict.setdefault(group_key, []).append(idx)\n",
        "\n",
        "# ============================\n",
        "# Merge Process\n",
        "# ============================\n",
        "merged_rows = []\n",
        "merge_count = 0\n",
        "\n",
        "cols_to_merge = [\n",
        "    c for c in mhg.columns\n",
        "    if c not in [\"MHGID\", \"BaseID\", \"GroupID_proximity\", \"issue_group\", \"is_mill\"]\n",
        "]\n",
        "\n",
        "for group_key, indices in group_dict.items():\n",
        "\n",
        "    # only 1 → no merge\n",
        "    if len(indices) == 1:\n",
        "        row = mhg.loc[indices[0]].copy()\n",
        "        base = row[\"BaseID\"]\n",
        "        is_mill = row[\"is_mill\"]\n",
        "\n",
        "        if is_mill:\n",
        "            # Mill lookup\n",
        "            row[\"Name\"] = mill_name_map.get(base, \"\")\n",
        "            row[\"Mill_Name\"] = mill_name_map.get(base, \"\")\n",
        "            row[\"Group Name\"] = mill_group_name_map.get(base, \"\")\n",
        "            row[\"GroupAirtableRecID\"] = mill_group_airtable_map.get(base, \"\")\n",
        "            row[\"Plot_group\"] = \"\"  # Mills don't have plot groups\n",
        "        else:\n",
        "            # Plot lookup\n",
        "            row[\"Name\"] = plot_name_map.get(base, \"\")\n",
        "            row[\"Mill_Name\"] = \"\"  # Plots don't have mill names\n",
        "            row[\"Group Name\"] = plot_group_name_map.get(base, \"\")\n",
        "            row[\"GroupAirtableRecID\"] = plot_group_airtable_map.get(base, \"\")\n",
        "\n",
        "            # Expand plot_group: get ALL plots in this GroupID_proximity\n",
        "            grp = row[\"GroupID_proximity\"]\n",
        "            if grp and grp in group_to_plots:\n",
        "                row[\"Plot_group\"] = \", \".join(sorted(group_to_plots[grp]))\n",
        "            else:\n",
        "                row[\"Plot_group\"] = base\n",
        "\n",
        "        merged_rows.append(row.to_dict())\n",
        "        continue\n",
        "\n",
        "    # merge happens\n",
        "    merge_count += (len(indices) - 1)\n",
        "    df = mhg.loc[indices]\n",
        "\n",
        "    rep = df.iloc[0].copy()\n",
        "    rep_base = rep[\"BaseID\"]\n",
        "    is_mill = rep[\"is_mill\"]\n",
        "\n",
        "    # merge unique values\n",
        "    for col in cols_to_merge:\n",
        "        vals = df[col].tolist()\n",
        "        uniq = sorted(set(sum([\n",
        "            v.split(\", \") if \", \" in v else [v] for v in vals\n",
        "        ], [])))\n",
        "        uniq = [v for v in uniq if v != \"\"]\n",
        "        rep[col] = \", \".join(uniq)\n",
        "\n",
        "    if is_mill:\n",
        "        # Mill lookup\n",
        "        rep[\"Name\"] = mill_name_map.get(rep_base, \"\")\n",
        "        rep[\"Mill_Name\"] = mill_name_map.get(rep_base, \"\")\n",
        "        rep[\"Group Name\"] = mill_group_name_map.get(rep_base, \"\")\n",
        "        rep[\"GroupAirtableRecID\"] = mill_group_airtable_map.get(rep_base, \"\")\n",
        "        rep[\"Plot_group\"] = \"\"  # Mills don't have plot groups\n",
        "    else:\n",
        "        # Plot lookup\n",
        "        rep[\"Name\"] = plot_name_map.get(rep_base, \"\")\n",
        "        rep[\"Mill_Name\"] = \"\"  # Plots don't have mill names\n",
        "        rep[\"Group Name\"] = plot_group_name_map.get(rep_base, \"\")\n",
        "        rep[\"GroupAirtableRecID\"] = plot_group_airtable_map.get(rep_base, \"\")\n",
        "\n",
        "        # Expand plot_group: get ALL plots in this GroupID_proximity\n",
        "        grp = rep[\"GroupID_proximity\"]\n",
        "        if grp and grp in group_to_plots:\n",
        "            rep[\"Plot_group\"] = \", \".join(sorted(group_to_plots[grp]))\n",
        "        else:\n",
        "            # Fallback: use BaseIDs from merged rows\n",
        "            plot_ids = sorted(set(df[\"BaseID\"].tolist()))\n",
        "            rep[\"Plot_group\"] = \", \".join(plot_ids)\n",
        "\n",
        "    # recalc grievance_count from updated grievance_IDs\n",
        "    if \"grievance_IDs\" in rep:\n",
        "        gid_list = rep[\"grievance_IDs\"].split(\", \")\n",
        "        gid_list = [x for x in gid_list if x != \"\"]\n",
        "        rep[\"grievance_count\"] = str(len(set(gid_list)))\n",
        "\n",
        "    merged_rows.append(rep.to_dict())\n",
        "\n",
        "# ============================\n",
        "# Build final DF\n",
        "# ============================\n",
        "result = pd.DataFrame(merged_rows)\n",
        "\n",
        "# Drop helper columns from output\n",
        "result = result.drop(columns=[\"BaseID\", \"issue_group\", \"is_mill\"], errors=\"ignore\")\n",
        "\n",
        "# Reorder columns untuk clarity (Name dan Mill_Name di depan)\n",
        "cols_order = [\"MHGID\", \"Name\", \"Mill_Name\", \"GroupID_proximity\", \"Plot_group\",\n",
        "              \"Group Name\", \"GroupAirtableRecID\"]\n",
        "other_cols = [c for c in result.columns if c not in cols_order]\n",
        "result = result[cols_order + other_cols]\n",
        "\n",
        "print(\"Jumlah sebelum merge :\", len(mhg))\n",
        "print(\"Jumlah sesudah merge :\", len(result))\n",
        "print(\"Total rows merged    :\", merge_count)\n",
        "\n",
        "# Show sample of mills\n",
        "mill_results = result[result[\"MHGID\"].str.startswith(\"PO100\", na=False)]\n",
        "if len(mill_results) > 0:\n",
        "    print(\"\\nSample Mill results:\")\n",
        "    print(mill_results[[\"MHGID\", \"Name\", \"Mill_Name\", \"Group Name\"]].head())\n",
        "\n",
        "# Show sample of plots\n",
        "plot_results = result[~result[\"MHGID\"].str.startswith(\"PO100\", na=False)]\n",
        "if len(plot_results) > 0:\n",
        "    print(\"\\nSample Plot results:\")\n",
        "    print(plot_results[[\"MHGID\", \"Name\", \"Plot_group\", \"Group Name\"]].head())\n",
        "\n",
        "# ============================\n",
        "# Export\n",
        "# ============================\n",
        "result.to_csv(\"MHG_Merged_Final.csv\", index=False)\n",
        "print(\"\\nFile saved as MHG_Merged_Final.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEhMqqlrt2bj",
        "outputId": "727faabd-80cb-4aab-9cca-77def647fa9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah sebelum merge : 1291\n",
            "Jumlah sesudah merge : 1051\n",
            "Total rows merged    : 240\n",
            "\n",
            "Sample Mill results:\n",
            "                MHGID           Name      Mill_Name       Group Name\n",
            "714  PO1000000017_soc  AGROPALMA/CPA  AGROPALMA/CPA        AGROPALMA\n",
            "715  PO1000000099_env      PERLABIAN      PERLABIAN            SIPEF\n",
            "716  PO1000000099_soc      PERLABIAN      PERLABIAN            SIPEF\n",
            "717  PO1000000109_env   PAMOL KLUANG   PAMOL KLUANG  IOI CORPORATION\n",
            "718  PO1000000109_soc   PAMOL KLUANG   PAMOL KLUANG  IOI CORPORATION\n",
            "\n",
            "Sample Plot results:\n",
            "       MHGID                         Name           Plot_group  \\\n",
            "0  10060_env            LADANG SSI SG ARA                10060   \n",
            "1  10136_env               Palong Timur 3  10136, 10138, 10140   \n",
            "2  10137_env  FGVPM Palong Timur 6 Estate          10137, 9033   \n",
            "3  10289_env        Ladang  Sungai Pinang                10289   \n",
            "4  10681_env    Puncak Niaga Holdings Bhd                10681   \n",
            "\n",
            "                Group Name  \n",
            "0          YPJ PLANTATIONS  \n",
            "1                    FELDA  \n",
            "2                      FGV  \n",
            "3  Ladang Rakyat Trengganu  \n",
            "4             Puncak Niaga  \n",
            "\n",
            "File saved as MHG_Merged_Final.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D. GROUPING BY THE GROUP NAME"
      ],
      "metadata": {
        "id": "yrE7RzM1X0eh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if the group name is same, merge. others/unknown, dont merged. (mills use proximity)"
      ],
      "metadata": {
        "id": "o8BbWjz9oRdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# ======================================================\n",
        "# CONFIG\n",
        "# ======================================================\n",
        "INPUT_FILE = \"MHG_Merged_Final.csv\"\n",
        "GPKG_FILE = \"plots_v2_20251209.gpkg\"\n",
        "MILLS_FILE = \"Mills-Grid view.csv\"  # File mills dengan kolom GPS/Latitude/Longitude\n",
        "OUTPUT_FILE = \"MHG_Final_GroupName_Proximity.csv\"\n",
        "\n",
        "MAX_DIST_KM = 50  # adjustable\n",
        "\n",
        "# ======================================================\n",
        "# LOAD DATA\n",
        "# ======================================================\n",
        "df = pd.read_csv(INPUT_FILE, dtype=str).fillna(\"\")\n",
        "\n",
        "# ======================================================\n",
        "# ISSUE GROUP\n",
        "# ======================================================\n",
        "def get_issue(mhgid):\n",
        "    if mhgid.endswith(\"_env\"):\n",
        "        return \"env\"\n",
        "    if mhgid.endswith(\"_soc\"):\n",
        "        return \"soc\"\n",
        "    return \"\"\n",
        "\n",
        "df[\"issue_group\"] = df[\"MHGID\"].apply(get_issue)\n",
        "\n",
        "# ======================================================\n",
        "# MILL IDENTIFIER\n",
        "# ======================================================\n",
        "def is_mill(mhgid):\n",
        "    return mhgid.startswith(\"PO100\")\n",
        "\n",
        "df[\"is_mill\"] = df[\"MHGID\"].apply(is_mill)\n",
        "\n",
        "# ======================================================\n",
        "# LOOKUP TABLES (PLOT & MILL NAME)\n",
        "# ======================================================\n",
        "mhgid_to_plot_name = df.set_index(\"MHGID\")[\"Name\"].to_dict()\n",
        "mhgid_to_mill_name = df.set_index(\"MHGID\")[\"Mill_Name\"].to_dict()\n",
        "\n",
        "# ======================================================\n",
        "# LOAD GEOMETRY - PLOTS\n",
        "# ======================================================\n",
        "gdf_plots = gpd.read_file(GPKG_FILE)[[\"ID\", \"geometry\"]]\n",
        "gdf_plots[\"ID\"] = gdf_plots[\"ID\"].astype(str)\n",
        "\n",
        "# ======================================================\n",
        "# LOAD GEOMETRY - MILLS\n",
        "# ======================================================\n",
        "mills_df = pd.read_csv(MILLS_FILE, dtype=str).fillna(\"\")\n",
        "\n",
        "# Parse koordinat mills\n",
        "def parse_mill_coords(row):\n",
        "    \"\"\"Extract lat, lon from mills data\"\"\"\n",
        "    try:\n",
        "        # Coba dari kolom Latitude, Longitude\n",
        "        if row.get(\"Latitude\") and row.get(\"Longitude\"):\n",
        "            lat = float(row[\"Latitude\"])\n",
        "            lon = float(row[\"Longitude\"])\n",
        "            return Point(lon, lat)\n",
        "\n",
        "        # Coba dari kolom GPS (format: \"lat, lon\")\n",
        "        if row.get(\"GPS\"):\n",
        "            coords = row[\"GPS\"].split(\",\")\n",
        "            if len(coords) == 2:\n",
        "                lat = float(coords[0].strip())\n",
        "                lon = float(coords[1].strip())\n",
        "                return Point(lon, lat)\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "mills_df[\"geometry\"] = mills_df.apply(parse_mill_coords, axis=1)\n",
        "mills_df = mills_df[mills_df[\"geometry\"].notna()]\n",
        "\n",
        "# Buat GeoDataFrame untuk mills\n",
        "gdf_mills = gpd.GeoDataFrame(\n",
        "    mills_df,\n",
        "    geometry=\"geometry\",\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# Kolom ID mills (sesuaikan dengan nama kolom di file Mills)\n",
        "# Asumsi ada kolom \"Mill ID\" atau \"ID\" atau \"Name\"\n",
        "if \"Mill ID\" in gdf_mills.columns:\n",
        "    gdf_mills[\"ID\"] = gdf_mills[\"Mill ID\"].astype(str)\n",
        "elif \"ID\" in gdf_mills.columns:\n",
        "    gdf_mills[\"ID\"] = gdf_mills[\"ID\"].astype(str)\n",
        "elif \"Name\" in gdf_mills.columns:\n",
        "    gdf_mills[\"ID\"] = gdf_mills[\"Name\"].astype(str)\n",
        "elif \"UML_ID\" in gdf_mills.columns: # FIX: Add check for 'UML_ID'\n",
        "    gdf_mills[\"ID\"] = gdf_mills[\"UML_ID\"].astype(str)\n",
        "\n",
        "gdf_mills = gdf_mills[[\"ID\", \"geometry\"]]\n",
        "\n",
        "# ======================================================\n",
        "# MERGE GEOMETRY KE MAIN DF\n",
        "# ======================================================\n",
        "df[\"BaseID\"] = df[\"MHGID\"].str.extract(r\"^(PO\\d+|\\d+)\")\n",
        "\n",
        "# Merge plots\n",
        "geo = df.merge(gdf_plots, left_on=\"BaseID\", right_on=\"ID\", how=\"left\", suffixes=(\"\", \"_plot\"))\n",
        "\n",
        "# Merge mills (untuk mill rows)\n",
        "geo = geo.merge(gdf_mills, left_on=\"BaseID\", right_on=\"ID\", how=\"left\", suffixes=(\"\", \"_mill\"))\n",
        "\n",
        "# Combine geometry: gunakan geometry_mill jika ada, kalau tidak pakai geometry\n",
        "geo[\"final_geometry\"] = geo.apply(\n",
        "    lambda r: r[\"geometry_mill\"] if pd.notna(r.get(\"geometry_mill\")) else r.get(\"geometry\"),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "geo = gpd.GeoDataFrame(geo, geometry=\"final_geometry\", crs=gdf_plots.crs)\n",
        "\n",
        "# Convert ke projected CRS untuk distance calculation\n",
        "geo = geo.to_crs(3857)\n",
        "geo[\"centroid\"] = geo.geometry.centroid\n",
        "\n",
        "# ======================================================\n",
        "# DISTANCE FUNCTION\n",
        "# ======================================================\n",
        "def dist_km(a, b):\n",
        "    return a.distance(b) / 1000.0\n",
        "\n",
        "# ======================================================\n",
        "# PROXIMITY FUNCTION (UNTUK PLOTS + MILLS)\n",
        "# ======================================================\n",
        "def split_by_proximity(entities_gdf, max_km):\n",
        "    \"\"\"\n",
        "    Return: list of index-lists\n",
        "    Each inner list = one proximity-based component\n",
        "    Works for both plots and mills\n",
        "    \"\"\"\n",
        "    cents = entities_gdf[\"centroid\"].tolist()\n",
        "    indices = entities_gdf.index.tolist()\n",
        "    n = len(indices)\n",
        "\n",
        "    if n <= 1:\n",
        "        return [indices]\n",
        "\n",
        "    adj = []\n",
        "    for i in range(n):\n",
        "        row = []\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                row.append(1)\n",
        "            else:\n",
        "                row.append(1 if dist_km(cents[i], cents[j]) <= max_km else 0)\n",
        "        adj.append(row)\n",
        "\n",
        "    graph = csr_matrix(adj)\n",
        "    n_components, labels = connected_components(graph, directed=False)\n",
        "    n_components = int(n_components)\n",
        "\n",
        "    components = []\n",
        "    for comp in range(n_components):\n",
        "        comp_indices = [indices[i] for i in range(n) if labels[i] == comp]\n",
        "        components.append(comp_indices)\n",
        "\n",
        "    return components\n",
        "\n",
        "# ======================================================\n",
        "# FINAL GROUPING\n",
        "# ======================================================\n",
        "final_rows = []\n",
        "merge_count = 0\n",
        "\n",
        "for issue, issue_df in geo.groupby(\"issue_group\"):\n",
        "\n",
        "    if issue == \"\":\n",
        "        continue\n",
        "\n",
        "    for group_id, sub in issue_df.groupby(\"GroupAirtableRecID\"):\n",
        "\n",
        "        # ==================================================\n",
        "        # CASE A: NO GroupAirtableRecID → fallback\n",
        "        # ==================================================\n",
        "        if group_id == \"\":\n",
        "            for _, r in sub.iterrows():\n",
        "                name = r[\"Mill_Name\"] if r[\"is_mill\"] else r[\"Name\"]\n",
        "                r[\"MHGID\"] = f\"{name}_{issue}\" if name else r[\"MHGID\"]\n",
        "                r[\"Group_MHGID\"] = r[\"MHGID\"]\n",
        "                final_rows.append(r.to_dict())\n",
        "            continue\n",
        "\n",
        "        # ==================================================\n",
        "        # CASE B: HAS GroupAirtableRecID\n",
        "        # ==================================================\n",
        "        # Pisahkan plots dan mills yang punya geometry\n",
        "        plots = sub[~sub[\"is_mill\"] & sub[\"centroid\"].notna()]\n",
        "        mills = sub[sub[\"is_mill\"] & sub[\"centroid\"].notna()]\n",
        "\n",
        "        # Mills tanpa geometry (fallback)\n",
        "        mills_no_geo = sub[sub[\"is_mill\"] & sub[\"centroid\"].isna()]\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # 0–1 entity (plot + mill) → no proximity split\n",
        "        # --------------------------------------------------\n",
        "        if len(plots) + len(mills) <= 1:\n",
        "            rep = sub.iloc[0].copy()\n",
        "            rep[\"MHGID\"] = f\"{rep['Group Name']}_{issue}\"\n",
        "            rep[\"Group_MHGID\"] = \", \".join(sorted(sub[\"MHGID\"].tolist()))\n",
        "\n",
        "            # BUILD Name & Mill_Name FROM Group_MHGID\n",
        "            plot_names, mill_names = [], []\n",
        "            for mid in rep[\"Group_MHGID\"].split(\",\"):\n",
        "                mid = mid.strip()\n",
        "                if mid.startswith(\"PO10\"):\n",
        "                    n = mhgid_to_mill_name.get(mid, \"\")\n",
        "                    if n:\n",
        "                        mill_names.append(n)\n",
        "                else:\n",
        "                    n = mhgid_to_plot_name.get(mid, \"\")\n",
        "                    if n:\n",
        "                        plot_names.append(n)\n",
        "\n",
        "            rep[\"Name\"] = \", \".join(sorted(set(plot_names)))\n",
        "            rep[\"Mill_Name\"] = \", \".join(sorted(set(mill_names)))\n",
        "\n",
        "            final_rows.append(rep.to_dict())\n",
        "            continue\n",
        "\n",
        "        # ==================================================\n",
        "        # PROXIMITY SPLIT (PLOTS + MILLS COMBINED)\n",
        "        # ==================================================\n",
        "        # Gabungkan plots dan mills yang punya geometry\n",
        "        entities_with_geo = pd.concat([plots, mills])\n",
        "\n",
        "        if len(entities_with_geo) == 0:\n",
        "            # Kalau semua tidak punya geometry, fallback\n",
        "            rep = sub.iloc[0].copy()\n",
        "            rep[\"MHGID\"] = f\"{rep['Group Name']}_{issue}\"\n",
        "            rep[\"Group_MHGID\"] = \", \".join(sorted(sub[\"MHGID\"].tolist()))\n",
        "\n",
        "            plot_names, mill_names = [], []\n",
        "            for mid in rep[\"Group_MHGID\"].split(\",\"):\n",
        "                mid = mid.strip()\n",
        "                if mid.startswith(\"PO10\"):\n",
        "                    n = mhgid_to_mill_name.get(mid, \"\")\n",
        "                    if n:\n",
        "                        mill_names.append(n)\n",
        "                else:\n",
        "                    n = mhgid_to_plot_name.get(mid, \"\")\n",
        "                    if n:\n",
        "                        plot_names.append(n)\n",
        "\n",
        "            rep[\"Name\"] = \", \".join(sorted(set(plot_names)))\n",
        "            rep[\"Mill_Name\"] = \", \".join(sorted(set(mill_names)))\n",
        "            final_rows.append(rep.to_dict())\n",
        "            continue\n",
        "\n",
        "        # Split by proximity (plots + mills together)\n",
        "        components = split_by_proximity(entities_with_geo, MAX_DIST_KM)\n",
        "\n",
        "        for comp_indices in components:\n",
        "            comp_df = geo.loc[comp_indices]\n",
        "\n",
        "            # Tambahkan mills tanpa geometry ke semua components\n",
        "            full_df = pd.concat([comp_df, mills_no_geo])\n",
        "\n",
        "            # FIX: Check if full_df is empty before proceeding\n",
        "            if full_df.empty:\n",
        "                continue\n",
        "\n",
        "            rep = full_df.iloc[0].copy()\n",
        "            rep[\"MHGID\"] = f\"{rep['Group Name']}_{issue}\"\n",
        "            rep[\"Group_MHGID\"] = \", \".join(sorted(full_df[\"MHGID\"].tolist()))\n",
        "\n",
        "            # BUILD Name & Mill_Name FROM Group_MHGID\n",
        "            plot_names, mill_names = [], []\n",
        "            for mid in rep[\"Group_MHGID\"].split(\",\"):\n",
        "                mid = mid.strip()\n",
        "                if mid.startswith(\"PO10\"):\n",
        "                    n = mhgid_to_mill_name.get(mid, \"\")\n",
        "                    if n:\n",
        "                        mill_names.append(n)\n",
        "                else:\n",
        "                    n = mhgid_to_plot_name.get(mid, \"\")\n",
        "                    if n:\n",
        "                        plot_names.append(n)\n",
        "\n",
        "            rep[\"Name\"] = \", \".join(sorted(set(plot_names)))\n",
        "            rep[\"Mill_Name\"] = \", \".join(sorted(set(mill_names)))\n",
        "\n",
        "            # Merge list columns\n",
        "            for col in [\"grievance_IDs\", \"plots\", \"mills\", \"sources\", \"issues\"]:\n",
        "                vals = []\n",
        "                for v in full_df[col]:\n",
        "                    if v:\n",
        "                        vals.extend([x.strip() for x in v.split(\",\")])\n",
        "                rep[col] = \", \".join(sorted(set(vals)))\n",
        "\n",
        "            # Plot_group (hanya dari plots)\n",
        "            plots_in_comp = comp_df[~comp_df[\"is_mill\"]]\n",
        "            if len(plots_in_comp) > 0:\n",
        "                rep[\"Plot_group\"] = \", \".join(sorted(set(plots_in_comp[\"BaseID\"].tolist())))\n",
        "            else:\n",
        "                rep[\"Plot_group\"] = \"\"\n",
        "\n",
        "            # grievance_count\n",
        "            gids = [g.strip() for g in rep[\"grievance_IDs\"].split(\",\") if g.strip()]\n",
        "            rep[\"grievance_count\"] = str(len(set(gids)))\n",
        "\n",
        "            if len(full_df) > 1:\n",
        "                merge_count += len(full_df) - 1\n",
        "\n",
        "            final_rows.append(rep.to_dict())\n",
        "\n",
        "# ======================================================\n",
        "# FINALIZE\n",
        "# ======================================================\n",
        "final_df = pd.DataFrame(final_rows)\n",
        "final_df = final_df.drop(\n",
        "    columns=[\"issue_group\", \"is_mill\", \"centroid\", \"final_geometry\",\n",
        "             \"geometry\", \"geometry_plot\", \"geometry_mill\", \"ID\", \"ID_plot\", \"ID_mill\"],\n",
        "    errors=\"ignore\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL GROUPING DONE (PLOTS + MILLS PROXIMITY)\")\n",
        "print(\"Merged rows :\", merge_count)\n",
        "print(\"Final rows  :\", len(final_df))\n",
        "print(\"=\" * 60)\n",
        "\n",
        "final_df.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"Saved: {OUTPUT_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL_Lo5_BWrH2",
        "outputId": "3e32f69b-8d65-43ea-93ea-867f1d2ce951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyogrio/raw.py:200: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured 3D MultiPolygon' is converted to 'MultiPolygon Z'\n",
            "  return ogr_read(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL GROUPING DONE (PLOTS + MILLS PROXIMITY)\n",
            "Merged rows : 313\n",
            "Final rows  : 738\n",
            "============================================================\n",
            "Saved: MHG_Final_GroupName_Proximity.csv\n"
          ]
        }
      ]
    }
  ]
}